{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score,roc_auc_score,make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('ADNI_Training_Q3_APOE_CollectionADNI1Complete 1Yr 1.5T_July22.2014.csv',low_memory=False)\n",
    "df = pd.read_csv('oasis_longitudinal.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>MRI ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Visit</th>\n",
       "      <th>MR Delay</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Hand</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>CDR</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR1</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR2</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>2</td>\n",
       "      <td>457</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR1</td>\n",
       "      <td>Demented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1678</td>\n",
       "      <td>0.736</td>\n",
       "      <td>1.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR2</td>\n",
       "      <td>Demented</td>\n",
       "      <td>2</td>\n",
       "      <td>560</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1738</td>\n",
       "      <td>0.713</td>\n",
       "      <td>1.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR3</td>\n",
       "      <td>Demented</td>\n",
       "      <td>3</td>\n",
       "      <td>1895</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1698</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  \\\n",
       "0  OAS2_0001  OAS2_0001_MR1  Nondemented      1         0   M    R   87    14   \n",
       "1  OAS2_0001  OAS2_0001_MR2  Nondemented      2       457   M    R   88    14   \n",
       "2  OAS2_0002  OAS2_0002_MR1     Demented      1         0   M    R   75    12   \n",
       "3  OAS2_0002  OAS2_0002_MR2     Demented      2       560   M    R   76    12   \n",
       "4  OAS2_0002  OAS2_0002_MR3     Demented      3      1895   M    R   80    12   \n",
       "\n",
       "   SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
       "0  2.0  27.0  0.0  1987  0.696  0.883  \n",
       "1  2.0  30.0  0.0  2004  0.681  0.876  \n",
       "2  NaN  23.0  0.5  1678  0.736  1.046  \n",
       "3  NaN  28.0  0.5  1738  0.713  1.010  \n",
       "4  NaN  22.0  0.5  1698  0.701  1.034  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['RID','studyID','ScanDate'],\n",
    " #       axis=1,inplace=True)\n",
    "#df.head()\n",
    "\n",
    "df = df.loc[df['Visit']==1] # use first visit data only because of the analysis we're doing\n",
    "df = df.reset_index(drop=True) # reset index after filtering first visit data\n",
    "df['M/F'] = df['M/F'].replace(['F','M'], [0,1]) # M/F column\n",
    "df['Group'] = df['Group'].replace(['Converted'], ['Demented']) # Target variable\n",
    "df['Group'] = df['Group'].replace(['Demented', 'Nondemented'], [1,0]) # Target variable\n",
    "df = df.drop(['MRI ID', 'Visit', 'Hand'], axis=1) # Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropna = df.dropna(axis=0, how='any')\n",
    "pd.isnull(df_dropna).sum()\n",
    "\n",
    "df.groupby(['EDUC'])['SES'].median()\n",
    "df[\"SES\"].fillna(df.groupby(\"EDUC\")[\"SES\"].transform(\"median\"), inplace=True)\n",
    "pd.isnull(df['SES']).value_counts()\n",
    "\n",
    "Y = df['Group'].values # Target for the model\n",
    "X = df[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use\n",
    "\n",
    "# splitting into three sets\n",
    "X_trainval, X_test, Y_trainval, Y_test = train_test_split(\n",
    "    X, Y, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "# Feature scaling\n",
    "scaler = MinMaxScaler().fit(X_trainval)\n",
    "X_trainval_scaled = scaler.transform(X_trainval)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "Y = df_dropna['Group'].values # Target for the model\n",
    "X = df_dropna[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use\n",
    "\n",
    "# splitting into three sets\n",
    "X_trainval_dna, X_test_dna, Y_trainval_dna, Y_test_dna = train_test_split(\n",
    "    X, Y, random_state=0)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = MinMaxScaler().fit(X_trainval_dna)\n",
    "X_trainval_scaled_dna = scaler.transform(X_trainval_dna)\n",
    "X_test_scaled_dna = scaler.transform(X_test_dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['Left-WM-hypointensities','Right-WM-hypointensities','Left-non-WM-hypointensities','Right-non-WM-hypointensities'],\n",
    " #       axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df.drop([Y,axis=]).copy(\n",
    "#y = df['y']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,X_test,y_train,y_test = train_test_split(X_encoded,y,random_state=42,startify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum(y_train)/len(y_train)\n",
    "#sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.87855\n",
      "[1]\tvalidation_0-aucpr:0.88180\n",
      "[2]\tvalidation_0-aucpr:0.90231\n",
      "[3]\tvalidation_0-aucpr:0.90230\n",
      "[4]\tvalidation_0-aucpr:0.90445\n",
      "[5]\tvalidation_0-aucpr:0.91300\n",
      "[6]\tvalidation_0-aucpr:0.92741\n",
      "[7]\tvalidation_0-aucpr:0.92585\n",
      "[8]\tvalidation_0-aucpr:0.93374\n",
      "[9]\tvalidation_0-aucpr:0.93860\n",
      "[10]\tvalidation_0-aucpr:0.93083\n",
      "[11]\tvalidation_0-aucpr:0.92932\n",
      "[12]\tvalidation_0-aucpr:0.93068\n",
      "[13]\tvalidation_0-aucpr:0.93687\n",
      "[14]\tvalidation_0-aucpr:0.93478\n",
      "[15]\tvalidation_0-aucpr:0.92450\n",
      "[16]\tvalidation_0-aucpr:0.92253\n",
      "[17]\tvalidation_0-aucpr:0.91450\n",
      "[18]\tvalidation_0-aucpr:0.91230\n",
      "[19]\tvalidation_0-aucpr:0.91355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic',missing= None,seed=42,use_label_encoder=False)\n",
    "clf_xgb.fit(X_trainval_scaled_dna,\n",
    "           Y_trainval_dna,\n",
    "           verbose=True,\n",
    "           early_stopping_rounds=10,\n",
    "           eval_metric='aucpr',\n",
    "           eval_set=[(X_test_scaled_dna,Y_test_dna)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
